{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 image encoded:  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/wAALCAAwADABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APwEu0skupUsLiWSBXIgkmhCO654LKGYKcckAnB4yetNgWB5QtzKyIfvMibiPwyP50hC4GH7c/nTT7U6NSzZBUbRnLEf16/SpLpJI3aI3KOF67DhevYcdye3rUe07QzH5SxHB+maRWZc7T1GKt3OpapJpEWjXHFtBM00amMAh3C5YnGSSFXr2UYqt5ciRLcBgAzEDDjORg9Oo6jnvz6GpGuL2Qq73DbrZRsZ5MMoBAAXJzwew6cn1qS7tdTureTxBeurCaf53knXzJGYud23O4jKtlgMA8E5IzBCszI+y3MiqhZiAfkGQN3HTnA545okWfCyTI4XO1SQccY4GfQEfmKDbSIFeRSFboy4PYE/oaj9qfmFgoKFfnO5gc8ccAe3Perl+9nNbWsVnA6lLY+b5ZZhJJubLnd907QuQBj5fxqidp5HHsaCSTkgfgKsQX3ljAgQkxhTlnAPOdxIYcjAHpUU6KjbVdW5OSvTr/8AW/WozkHBFX7yPVpNKg1C706VrUKbaC8ZG2bgfMKhuhYBxkdgw471Ugie5IghiJfJORn2/QVHRjNK6ujGORSCpwVYcg+lJTpXEm1iWLbcMWbOfTHtjApXneSNA7OWQFQxfOF7Aenf86R/LYlk+XPO3HA9hyaaQR1p8kpeNIjtOwHawznB5x+Bz+Z9qbHJJDIssTlWUgqynBBHcGrmk3sFuJkurp4h9mmERjso5izsu3adxG0EfxDJXqASa//Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3016\\2497224119.py:89: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  batch = torch.Tensor(batch).unsqueeze(1)\n"
     ]
    }
   ],
   "source": [
    "from Unet import build_model\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import base64\n",
    "import sys\n",
    "import os\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "def ce_loss(y_true, y_pred):\n",
    "    term_0 = (1 - y_true) * K.log(1 - y_pred + K.epsilon())\n",
    "    term_1 = y_true * K.log(y_pred + K.epsilon())\n",
    "    out = -K.mean(term_0 + term_1)\n",
    "    return out\n",
    "\n",
    "def acc_met(y_true,y_pred):\n",
    "    out = K.mean(K.equal(y_true, y_pred))\n",
    "    return out\n",
    "\n",
    "def sensitivity(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    neg_y_pred = 1 - y_pred_f\n",
    "    tp = K.sum(y_true_f * y_pred_f)\n",
    "    fn = K.sum(y_true_f * neg_y_pred)\n",
    "    return tp / (tp+fn+K.epsilon())\n",
    "\n",
    "def specificity(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    neg_y_true = 1 - y_true_f\n",
    "    neg_y_pred = 1 - y_pred_f\n",
    "    fp = K.sum(neg_y_true * y_pred_f)\n",
    "    tn = K.sum(neg_y_true * neg_y_pred)\n",
    "    return tn / (tn + fp + K.epsilon())\n",
    "\n",
    "\n",
    "# Give Image in RGB Format\n",
    "def run(img_path):\n",
    "    # print(image_path)\n",
    "    # img_path = sys.argv[1]\n",
    "    # print(img_path)\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    # print(img)\n",
    "    # gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # print(gray_img)\n",
    "    # print(img)\n",
    "    # Encode the processed image as base64\n",
    "    # _, buffer = cv2.imencode('.jpg', gray_img)\n",
    "    # encoded_image = base64.b64encode(buffer).decode('utf-8')\n",
    "    \n",
    "    # print(encoded_image)  # Print the base64 encoded image data\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit = 8, tileGridSize=(8,8))\n",
    "    if img.shape[0] == 3:\n",
    "        img = img[1,:,:]\n",
    "    elif img.shape[2] == 3:\n",
    "        img = img[:,:,1]\n",
    "    \n",
    "    m,n = img.shape\n",
    "    img = clahe.apply(img)\n",
    "    \n",
    "    if os.listdir(\"./Model\")[0][-1] == 't':\n",
    "        # print(img.shape)\n",
    "        final_res = torch.zeros(img.shape)\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        device = torch.device(device)\n",
    "        model = build_model().to(device)\n",
    "        model_filename = \"./Model/Model.pt\"\n",
    "        state = torch.load(model_filename,map_location=torch.device(device))\n",
    "        model.load_state_dict(state['model_state_dict'])\n",
    "        model.eval()\n",
    "        batch = []\n",
    "        \n",
    "        for i in range(0,m,8):\n",
    "            for j in range(0,n,8):\n",
    "                if(i+48 > m) or (j+48 > n):\n",
    "                    continue\n",
    "\n",
    "                cimg = img[i:i+48,j:j+48]\n",
    "\n",
    "                batch.append(cimg)\n",
    "                \n",
    "        batch = torch.Tensor(batch).unsqueeze(1)\n",
    "        with torch.no_grad():\n",
    "            out = model(batch.to(device))\n",
    "        \n",
    "        # print(out.shape)\n",
    "        oc = 0\n",
    "        for i in range(0,m,8):\n",
    "            for j in range(0,n,8):\n",
    "                if(i+48 > m) or (j+48 > n):\n",
    "                    continue\n",
    "                final_res[i:i+48,j:j+48] = final_res[i:i+48,j:j+48] + out[oc][0].cpu().detach()\n",
    "                oc+=1\n",
    "            \n",
    "        if final_res is None:\n",
    "            raise ValueError(\"final_res is not initialized. Model may not have produced any output.\")\n",
    "        else:\n",
    "            final_res = (final_res*255).numpy().astype(np.uint8)\n",
    "            _, buffer = cv2.imencode('.jpg', final_res)\n",
    "            encoded_image = base64.b64encode(buffer).decode('utf-8')\n",
    "            if encoded_image is None:\n",
    "                raise ValueError(\"final_res is not initialized. Model may not have produced any output.\")\n",
    "            else:\n",
    "                print(\"1 image encoded: \", encoded_image)  # Print the base64 encoded image data\n",
    "        \n",
    "        # return final_res.numpy()\n",
    "    \n",
    "    else:\n",
    "        seg_model = load_model(\"./UNet_JND_EOphtha.h5\", custom_objects={\"ce_loss\":ce_loss, \"acc_met\":acc_met, \"sensitivity\": sensitivity, \"specificity\": specificity})\n",
    "        final_res = np.zeros(img.shape)\n",
    "        batch = []\n",
    "        for i in range(0,m,8):\n",
    "            for j in range(0,n,8):\n",
    "                if(i+48 > m) or (j+48 > n):\n",
    "                    continue\n",
    "\n",
    "                cimg = img[i:i+48,j:j+48]\n",
    "                batch.append(cimg)\n",
    "        \n",
    "        batch = np.array(batch)\n",
    "        batch = np.expand_dims(batch,axis=-1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = seg_model.predict(batch,verbose=False)\n",
    "        for i in range(0,out.shape[0]):\n",
    "            final_res[i:i+48,j:j+48] = final_res[i:i+48,j:j+48] + out[0,:,:,0]\n",
    "\n",
    "        if final_res is None:\n",
    "            raise ValueError(\"final_res is not initialized. Model may not have produced any output.\")\n",
    "        else:\n",
    "            final_res = final_res.astype(np.uint8)\n",
    "            _, buffer = cv2.imencode('.jpg', final_res)\n",
    "            encoded_image = base64.b64encode(buffer).decode('utf-8')\n",
    "            if encoded_image is None:\n",
    "                raise ValueError(\"final_res is not initialized. Model may not have produced any output.\")\n",
    "            else:\n",
    "                print(\"2 image encoded: \", encoded_image)  # Print the base64 encoded image data\n",
    "        \n",
    "        # return final_res\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # Get the current directory of the Python script\n",
    "    current_directory = os.path.dirname(os.path.abspath('run.py'))\n",
    "\n",
    "    # Navigate one level up\n",
    "    parent_directory = os.path.abspath(os.path.join(current_directory, os.pardir))\n",
    "\n",
    "    # Construct the path to the image file\n",
    "    image_path = os.path.join(parent_directory, 'epotha.jpg')\n",
    "    run(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = cv2.imread('../epotha.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cv2.GaussianBlur(t,(5,5),0)\n",
    "out = cv2.threshold(out,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cv2.GaussianBlur(t,(5,5),cv2.BORDER_DEFAULT)\n",
    "_,out = cv2.threshold(out,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(y_true, y_pred):\n",
    "    term_0 = (1 - y_true) * K.log(1 - y_pred + K.epsilon())\n",
    "    term_1 = y_true * K.log(y_pred + K.epsilon())\n",
    "    out = -K.mean(term_0 + term_1)\n",
    "    return out\n",
    "\n",
    "def acc_met(y_true,y_pred):\n",
    "    out = K.mean(K.equal(y_true, y_pred))\n",
    "    return out\n",
    "\n",
    "def sensitivity(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    neg_y_pred = 1 - y_pred_f\n",
    "    tp = K.sum(y_true_f * y_pred_f)\n",
    "    fn = K.sum(y_true_f * neg_y_pred)\n",
    "    return tp / (tp+fn+K.epsilon())\n",
    "\n",
    "def specificity(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    neg_y_true = 1 - y_true_f\n",
    "    neg_y_pred = 1 - y_pred_f\n",
    "    fp = K.sum(neg_y_true * y_pred_f)\n",
    "    tn = K.sum(neg_y_true * neg_y_pred)\n",
    "    return tn / (tn + fp + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m----> 2\u001b[0m seg_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./Model/Model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mce_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mce_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43macc_met\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43macc_met\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msensitivity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msensitivity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspecificity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecificity\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:155\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    151\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:145\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m _deserialize_nested_config(losses\u001b[38;5;241m.\u001b[39mdeserialize, loss_config)\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Ensure backwards compatibility for losses in legacy H5 files\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43m_resolve_compile_arguments_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Recover metrics.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:245\u001b[0m, in \u001b[0;36m_resolve_compile_arguments_compat\u001b[1;34m(obj, obj_config, module)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resolves backwards compatibility issues with training config arguments.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03mThis helper function accepts built-in Keras modules such as optimizers,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03mthis does nothing.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m obj \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mALL_OBJECTS_DICT:\n\u001b[1;32m--> 245\u001b[0m     obj \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mget(\u001b[43mobj_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "seg_model = load_model(\"./Model/Model.h5\", custom_objects={\"ce_loss\":ce_loss, \"acc_met\":acc_met, \"sensitivity\": sensitivity, \"specificity\": specificity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
